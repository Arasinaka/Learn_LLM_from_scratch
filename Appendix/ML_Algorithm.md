## 浅议机器学习算法

机器学习非常擅长以下三个任务

* 回归(regression）
* 分类(classification)
* 聚类(clustering)

### 回归

简单的说，回归就是处理**连续数据**，如**时间序列数据**时使用的技术。
例子：过去几天的股价数据，如下表所示：

| 日期 | 股价 |
| --- | --- |
| 昨天 | ￥1000 |  
| 2天前 | ￥1100 |
| 3天前 | ￥1070 |

从这样的数据中学习它的趋势，求出“明天的股价会变成多少？”的方法就是**回归**。

### 分类

检查邮件的内容，然后判断它是不是垃圾邮件，就是一个典型的分类问题。

例子：根据邮件内容，以及这封邮件是否属于垃圾邮件这些数据来进行学习。

| 邮件内容 | 是否为垃圾邮件 |
| --- | --- |
| 辛苦啦！下个周日我们去玩吧..... | No |  
| 加我为好友吧。这里有我的照片哟！http://... | Yes |
| 恭喜您赢得夏威夷旅游大奖... | Yes |

在开始学习之前，我们必须像上述这张表这样，先手动标记邮件是否为垃圾邮件。这样打标签的工作，需要人工介入。

### 聚类

聚类与分类相似，又有不同。
例子：假设在100名学生的学校进行摸底考试，然后根据考试成绩把100名学生分成几组，根据分组结果，我们能得出某组偏重理科、某组偏重文科这样有意义的结论。

| 学生编号| 英语分数| 数学分数 | 语文分数| 物理分数 |
| --- | --- | --- | --- | --- |
| A-1 | 100 | 98 | 89 | 96 |
| A-2 | 77 | 98 | 69 | 98 |
| A-3 | 99 | 56 | 99 | 61 |

Tips: 聚类与分类的区别在于数据带不带**标签**.



### 常用的激活函数

常用的激活函数有 Sigmoid、ReLU、Tanh 等，它们的选择取决于模型的需求和数据的特点。

* Sigmoid：Sigmoid 函数是一种 S 型函数，它的输出范围在0到1之间。Sigmoid函数在神经网络中常用于二分类问题，因为它可以将输入映射到0到1之间的概率值。Sigmoid函数的缺点是容易出现梯度消失和梯度爆炸的问题，因此在深度神经网络中不太常用。
* ReLU：ReLU函数是一种分段线性函数，它的输出要么是0，要么是输入的原始值。ReLU函数在神经网络中常用于多分类问题，因为它可以避免梯度消失和梯度爆炸的问题。ReLU函数的优点是计算简单、速度快，但它的缺点是可能会导致神经元死亡，即某些神经元的输出永远为0。
* Tanh：Tanh 函数是一种S型函数，它的输出范围在-1到1之间。Tanh函数在神经网络中常用于多分类问题，因为它可以将输入映射到-1到1之间的概率值。Tanh 函数的优点是计算简单、速度快，但它的缺点是也容易出现梯度消失和梯度爆炸的问题。
  在选择激活函数时，我们需要考虑模型的需求、数据的特点和计算资源的限制等因素。一般来说，如果模型需要处理二分类问题，可以选择Sigmoid函数；如果模型需要处理多分类问题，可以选择ReLU函数或Tanh函数。如果计算资源有限，可以选择计算简单、速度快的激活函数，如ReLU函数。

