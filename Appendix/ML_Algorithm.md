## 浅议机器学习算法

机器学习非常擅长以下三个任务

* 回归(regression）
* 分类(classification)
* 聚类(clustering)

### 回归

简单的说，回归就是处理**连续数据**，如**时间序列数据**时使用的技术。
例子：过去几天的股价数据，如下表所示：

| 日期 | 股价 |
| --- | --- |
| 昨天 | ￥1000 |  
| 2天前 | ￥1100 |
| 3天前 | ￥1070 |

从这样的数据中学习它的趋势，求出“明天的股价会变成多少？”的方法就是**回归**。

### 分类

检查邮件的内容，然后判断它是不是垃圾邮件，就是一个典型的分类问题。

例子：根据邮件内容，以及这封邮件是否属于垃圾邮件这些数据来进行学习。

| 邮件内容 | 是否为垃圾邮件 |
| --- | --- |
| 辛苦啦！下个周日我们去玩吧..... | No |  
| 加我为好友吧。这里有我的照片哟！http://... | Yes |
| 恭喜您赢得夏威夷旅游大奖... | Yes |

在开始学习之前，我们必须像上述这张表这样，先手动标记邮件是否为垃圾邮件。这样打标签的工作，需要人工介入。

### 聚类

聚类与分类相似，又有不同。
例子：假设在100名学生的学校进行摸底考试，然后根据考试成绩把100名学生分成几组，根据分组结果，我们能得出某组偏重理科、某组偏重文科这样有意义的结论。

| 学生编号| 英语分数| 数学分数 | 语文分数| 物理分数 |
| --- | --- | --- | --- | --- |
| A-1 | 100 | 98 | 89 | 96 |
| A-2 | 77 | 98 | 69 | 98 |
| A-3 | 99 | 56 | 99 | 61 |

Tips: 聚类与分类的区别在于数据带不带**标签**.

### 监督学习与无监督学习

使用有标签的数据进行的学习称为**监督学习**，反之，称为**无监督学习**。回归和分类为监督学习，而聚类是无监督学习。

### MLP遇到的问题

让我们先回顾一下上文，我们用计算机模拟了人脑的生理结构和学习过程，发展出了经典的神经网络结构——多层感知机（MLP）。
MLP是一种基础的神经网络模型，它在很多问题上都表现得相当出色。然而，MLP也有一些明显的缺点：

1. 参数量大、训练难度大：MLP的网络结构中，每个神经元都和上一层中的所有节点连接，这导致参数量大，训练过程相对较耗时。
2. 丢失空间信息：MLP会丢失像素间的空间信息，只接受向量输入，这意味着，对于图像这种空间信息丰富的数据，MLP的运行模式可能不适合

为了解决这些问题，业界采取了一些策略：

1. 引入卷积神经网络（CNN）：CNN通过局部稀疏连接和接受矩阵输入的方式，利用像素间空间关系，有效地减少了参数量，同时保留了图像的空间信息
2. 使用Transformer模型：Transformer模型通过自注意力机制，可以捕获输入数据的全局依赖关系，从而提高模型的性能。

CNN和Transformer，包括后文提到的RNN/LSTM都是神经网络，就是特征提取器。站在2023年这个时间节点，CNN解决了大多数计算机视觉邻域的问题。而Transformer，是当红炸子鸡，正在大规模的运用在NLP邻域，并且越来越多的和其他模型结合，应用到其他邻域，比如CV。

