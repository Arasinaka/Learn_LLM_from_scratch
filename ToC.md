# Table of Content

## Chapt 1 缘起

### 1.1 为什么要学AI/ML

### 1.2 人脑是如何工作的

### 1.3 数学知识

### 1.4 Reference

## Chapt 2 机器学习基础知识

### 2.1 目标

### 2.2 感知机

### 2.3 逻辑回归

### 2.4 分类问题

### 2.5 总结

### 2.6 Reference

## Chapt 3 机器视觉（CV）

### 3.1 目标

### 3.2 卷积神经网络（CNN）

### 3.3 几个著名的神经网络模型

### 3.4 总结

### 3.5 Reference

## Chapt 4 自然语言处理（NLP）

### 4.1 目标

### 4.2 循环神经网络RNN

### 4.3 LSTM

### 4.4 初见Transform

### 4.5 总结

### 4.6 Reference

## Chapt 5 注意力（Attention）模型

### 5.1 目标

### 5.2

## Chapt 6 Transformer

### 5.1 目标

### 5.2 注意力（Attention）

### 5.3 Transform 网络结构

### 5.4 Encoder

### 5.5 Decoder

### 5.6 代码实现

### 5.7 总结

## Chapt 7 大语言模型（LLM）革命前夜

### 6.1 目标

### 6.2 从Word Embedding到Bert

### 6.3 深入Bert

### 6.4 从Pre-Train Model+Fune tuning到AGI

### 6.5 深入ChatGPT

### 6.6 总结

### 6.7 Reference

## Chapt 8 大语言模型（LLM）

### 8.1 目标

### 8.2 深入探讨一下LLM

#### 8.2.1 LLM两种实现方式

#### 8.2.2 LLM知识储存在哪里

#### 8.2.3 如何修改LLM的知识











